{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with arXiv Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval-augmented generation (RAG) provides large language models additional helpful information in a prompt that is retrieved when a user submits a query.\n",
    "\n",
    "This guide uses Atlas as a data layer for retrieval, followed by LLM inference using the information queried from our Atlas Dataset via vector search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nomic login nk-rKYMrmxBV5F7B5FK-XkFPGDh3G91b_F0eA9ZtVR-BLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Atlas Dataset\n",
    "\n",
    "Let's start with a collection with PDFs and chunk them into snippets to be fetched for retrieval.\n",
    "\n",
    "For this example, we will download PDFs from the open-access paper repository arXiv.\n",
    "\n",
    "Make sure these libraries are installed to your python environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2 requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can download PDFs from arxiv and prepare them as a dataset of paper chunks. This way, we will be able to retrieve specific relevant snippets from papers (instead of entire papers) later on when running RAG with an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import PyPDF2\n",
    "\n",
    "ARXIV_PAPERS = [\n",
    "    (\"1706.03762\", \"Attention Is All You Need\"),\n",
    "    (\"1512.03385\", \"Deep Residual Learning\"),\n",
    "    (\"1810.04805\", \"BERT\"),\n",
    "    (\"2005.14165\", \"GPT-3\"),\n",
    "    (\"1412.6980\", \"Adam\"),\n",
    "    (\"1406.2661\", \"GANs\"),\n",
    "    (\"1505.04597\", \"U-Net\"),\n",
    "    (\"2204.06125\", \"DALL-E 2\"),\n",
    "    (\"2112.10752\", \"Stable Diffusion\")\n",
    "]\n",
    "\n",
    "# load text from PDFs into a list of dicts called 'data'\n",
    "# each containing a text chunk plus metadata\n",
    "data = []\n",
    "text_chunk_size = 500\n",
    "for paper_id, title in ARXIV_PAPERS:\n",
    "    print(\"Downloading\", title)\n",
    "    pdf = PyPDF2.PdfReader(io.BytesIO(requests.get(f\"https://arxiv.org/pdf/{paper_id}.pdf\").content))    \n",
    "    for page_num, page in enumerate(pdf.pages):\n",
    "        text = page.extract_text()\n",
    "        for i in range(0, len(text), text_chunk_size):\n",
    "            chunk = text[i:i + text_chunk_size].strip()\n",
    "            data.append({\n",
    "                \"filename\": f\"arxiv_{paper_id}.pdf\",\n",
    "                \"title\": title,\n",
    "                \"page_number\": page_num + 1,\n",
    "                \"text\": chunk\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data to make sure it looks alright:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Dataset to Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nomic import atlas\n",
    "\n",
    "atlas_dataset = atlas.map_data(\n",
    "    data=data,\n",
    "    indexed_field=\"text\",\n",
    "    identifier=\"rag-pdf-dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll get an email when your data map is built!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Over Your Data Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have an Atlas Dataset, you can use it as the data layer for your application. Our vector search endpoint returns the k-most semantically similar items from your Atlas Dataset based on a query.\n",
    "\n",
    "This example function makes an API call to Atlas's vector search endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def retrieve_context(query: str, projection_id: str, k: int, fields: list[str]) -> list:\n",
    "    \"\"\"Retrieve semantically similar items from Atlas based on a query.\"\"\"\n",
    "    response = requests.post(\n",
    "        'https://api-atlas.nomic.ai/v1/query/topk',\n",
    "        headers={'Authorization': f'Bearer {os.environ.get(\"NOMIC_API_KEY\")}'},\n",
    "        json={\n",
    "            'projection_id': projection_id,\n",
    "            'k': k,\n",
    "            'query': query,\n",
    "            'fields': fields\n",
    "        }\n",
    "    )\n",
    "    return response.json()['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important parameters for this endpoint are:\n",
    "\n",
    "• query: The text query to search against\n",
    "\n",
    "• k: Number of similar items to return\n",
    "\n",
    "• fields: List of fields from your dataset to return in the response\n",
    "\n",
    "• projection_id: The unique identifier for your Atlas map (you can find it on the dataset page for any dataset on your [Atlas Dashboard](https://docs.nomic.ai/atlas/introduction/quick-start#atlas-dashboard)\n",
    "\n",
    "For example, here is the output for retrieve_content on the previously created dataset of ML papers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update this with the projection ID\n",
    "# on the dataset page for your new Atlas map\n",
    "my_map_projection_id = \"a3392b83-a135-4e4c-addb-a8b71ca59f5c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_data = retrieve_context(\n",
    "    \"What is attention in deep learning?\", # Query\n",
    "    my_map_projection_id,  # Your Atlas projection ID\n",
    "    3,  # Return top 3 results\n",
    "    [\"title\", \"text\"]  # Fields to retrieve\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the retrieved data to make sure it looks alright:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End RAG with the Data Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a retrieval function for our data map, we can now perform end-to-end RAG.\n",
    "\n",
    "## Install Ollama\n",
    "\n",
    "We will run LLM generation using Ollama, which you can download here.\n",
    "\n",
    "Once ollama is installed to your machine, install Llama 3.2 1b at your terminal with \n",
    "\n",
    "`ollama pull llama3.2:1b` \n",
    "\n",
    "## Full Code Example\n",
    "\n",
    "We now add an additional function generate_response which sends the result of an Atlas Dataset retrieval and sends it to an Ollama LLM (at the default Ollama endpoint http://localhost:11434/api/chat).\n",
    "\n",
    "The response is then assembled into a single string for the user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def retrieve_context(query: str, projection_id: str, k: int, fields: list[str]) -> list:\n",
    "    \"\"\"Retrieve semantically similar items from Atlas based on a query.\"\"\"\n",
    "    response = requests.post(\n",
    "        'https://api-atlas.nomic.ai/v1/query/topk',\n",
    "        headers={'Authorization': f'Bearer {os.environ.get(\"NOMIC_API_KEY\")}'},\n",
    "        json={\n",
    "            'projection_id': projection_id,\n",
    "            'k': k,\n",
    "            'query': query,\n",
    "            'fields': fields\n",
    "        }\n",
    "    )\n",
    "    return response.json()['data']\n",
    "\n",
    "\n",
    "def generate_response(retrieved_data: list, query: str) -> str:\n",
    "    \"\"\"Generate a response using Ollama based on retrieved data and query.\"\"\"\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/chat',\n",
    "        json={\n",
    "            'model': 'llama3.2:1b',\n",
    "            'messages': [{\n",
    "                'role': 'user',\n",
    "                'content': f\"Context:\\n{retrieved_data}\\n\\nQuestion: {query}\"\n",
    "            }]\n",
    "        }\n",
    "    )\n",
    "    return ''.join(\n",
    "        json.loads(line)['message']['content']\n",
    "        for line in response.text.strip().split('\\n')\n",
    "        if line and not json.loads(line).get('done', False)\n",
    "    )\n",
    "\n",
    "query = \"What is attention in deep learning?\"\n",
    "\n",
    "retrieved_data = retrieve_context(\n",
    "    query,\n",
    "    my_map_projection_id,  # Your Atlas projection ID\n",
    "    3,  # Return top 3 results\n",
    "    [\"title\", \"text\"]  # Fields to retrieve\n",
    ")\n",
    "\n",
    "response = generate_response(retrieved_data, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print the RAG response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Q: {query}\\nA: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
